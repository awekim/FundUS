{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447e9399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-1.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting shapely\n",
      "  Downloading shapely-2.0.7-cp39-cp39-win_amd64.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (21.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (from geopandas) (1.26.3)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas)\n",
      "  Downloading pyogrio-0.11.1-cp39-cp39-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (from geopandas) (24.2)\n",
      "Collecting pyproj>=3.3.0 (from geopandas)\n",
      "  Downloading pyproj-3.6.1-cp39-cp39-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.conda\\envs\\gpu_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading geopandas-1.0.1-py3-none-any.whl (323 kB)\n",
      "Downloading shapely-2.0.7-cp39-cp39-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 18.8 MB/s eta 0:00:00\n",
      "Downloading pyogrio-0.11.1-cp39-cp39-win_amd64.whl (19.2 MB)\n",
      "   ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 6.3/19.2 MB 48.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 7.9/19.2 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.2/19.2 MB 33.7 MB/s eta 0:00:00\n",
      "Downloading pyproj-3.6.1-cp39-cp39-win_amd64.whl (6.1 MB)\n",
      "   ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.1/6.1 MB 92.5 MB/s eta 0:00:00\n",
      "Installing collected packages: shapely, pyproj, pyogrio, geopandas\n",
      "Successfully installed geopandas-1.0.1 pyogrio-0.11.1 pyproj-3.6.1 shapely-2.0.7\n"
     ]
    }
   ],
   "source": [
    "# !pip install geopandas shapely pyarrow pandas requests tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66bda4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: I:/Data_for_practice/Rfiles/FundUS/nsf_aff_with_tract_names.csv\n",
      "Matched tracts: 9247\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import requests\n",
    "\n",
    "\n",
    "INPUT_CSV = \"I:/Data_for_practice/Rfiles/FundUS/nsf_aff.csv\"\n",
    "OUTPUT_CSV = \"I:/Data_for_practice/Rfiles/FundUS/nsf_aff_with_tract_names.csv\"\n",
    "CACHE_DIR = \"./tiger_cache\"\n",
    "TIGER_YEAR = 2023\n",
    "\n",
    "\n",
    "STATEFP_TO_NAME = {\n",
    "    \"01\": \"Alabama\", \"02\": \"Alaska\", \"04\": \"Arizona\", \"05\": \"Arkansas\", \"06\": \"California\",\n",
    "    \"08\": \"Colorado\", \"09\": \"Connecticut\", \"10\": \"Delaware\", \"11\": \"District of Columbia\",\n",
    "    \"12\": \"Florida\", \"13\": \"Georgia\", \"15\": \"Hawaii\", \"16\": \"Idaho\", \"17\": \"Illinois\",\n",
    "    \"18\": \"Indiana\", \"19\": \"Iowa\", \"20\": \"Kansas\", \"21\": \"Kentucky\", \"22\": \"Louisiana\",\n",
    "    \"23\": \"Maine\", \"24\": \"Maryland\", \"25\": \"Massachusetts\", \"26\": \"Michigan\", \"27\": \"Minnesota\",\n",
    "    \"28\": \"Mississippi\", \"29\": \"Missouri\", \"30\": \"Montana\", \"31\": \"Nebraska\", \"32\": \"Nevada\",\n",
    "    \"33\": \"New Hampshire\", \"34\": \"New Jersey\", \"35\": \"New Mexico\", \"36\": \"New York\",\n",
    "    \"37\": \"North Carolina\", \"38\": \"North Dakota\", \"39\": \"Ohio\", \"40\": \"Oklahoma\",\n",
    "    \"41\": \"Oregon\", \"42\": \"Pennsylvania\", \"44\": \"Rhode Island\", \"45\": \"South Carolina\",\n",
    "    \"46\": \"South Dakota\", \"47\": \"Tennessee\", \"48\": \"Texas\", \"49\": \"Utah\", \"50\": \"Vermont\",\n",
    "    \"51\": \"Virginia\", \"53\": \"Washington\", \"54\": \"West Virginia\", \"55\": \"Wisconsin\", \"56\": \"Wyoming\",\n",
    "    \"60\": \"American Samoa\", \"66\": \"Guam\", \"69\": \"Northern Mariana Islands\", \"72\": \"Puerto Rico\", \"78\": \"U.S. Virgin Islands\"\n",
    "}\n",
    "\n",
    "\n",
    "def download_extract(url: str, out_dir: str) -> str:\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 이미 shp 있으면 스킵\n",
    "    if any(out_dir.glob(\"*.shp\")):\n",
    "        return str(out_dir)\n",
    "\n",
    "    r = requests.get(url, timeout=240)\n",
    "    r.raise_for_status()\n",
    "    with zipfile.ZipFile(BytesIO(r.content)) as z:\n",
    "        z.extractall(out_dir)\n",
    "\n",
    "    return str(out_dir)\n",
    "\n",
    "\n",
    "def tiger_tract_url(year: int, statefp: str) -> str:\n",
    "    # Tract는 \"주 단위\" 파일만 존재\n",
    "    return f\"https://www2.census.gov/geo/tiger/TIGER{year}/TRACT/tl_{year}_{statefp}_tract.zip\"\n",
    "\n",
    "\n",
    "def load_state_tracts(year: int, statefp: str, cache_dir: str) -> gpd.GeoDataFrame:\n",
    "    folder = Path(cache_dir) / f\"tl_{year}_{statefp}_tract\"\n",
    "    download_extract(tiger_tract_url(year, statefp), folder)\n",
    "\n",
    "    shp = next(folder.glob(\"*.shp\"), None)\n",
    "    if shp is None:\n",
    "        raise FileNotFoundError(f\"Tract shapefile not found in {folder}\")\n",
    "\n",
    "    gdf = gpd.read_file(shp).to_crs(epsg=4326)\n",
    "\n",
    "    # NAMELSAD = 사람이 읽는 tract 이름(예: \"Census Tract 1.01\")\n",
    "    keep = [\"GEOID\", \"STATEFP\", \"COUNTYFP\", \"TRACTCE\", \"NAMELSAD\", \"geometry\"]\n",
    "    gdf = gdf[keep].rename(\n",
    "        columns={\n",
    "            \"GEOID\": \"tract_geoid\",\n",
    "            \"STATEFP\": \"statefp\",\n",
    "            \"COUNTYFP\": \"countyfp\",\n",
    "            \"TRACTCE\": \"tractce\",\n",
    "            \"NAMELSAD\": \"tract_name\",\n",
    "        }\n",
    "    )\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def load_us_counties(year: int, cache_dir: str) -> gpd.GeoDataFrame:\n",
    "    # County는 전국 단일 파일이 존재\n",
    "    url = f\"https://www2.census.gov/geo/tiger/TIGER{year}/COUNTY/tl_{year}_us_county.zip\"\n",
    "    folder = Path(cache_dir) / f\"tl_{year}_us_county\"\n",
    "    download_extract(url, folder)\n",
    "\n",
    "    shp = next(folder.glob(\"*.shp\"), None)\n",
    "    if shp is None:\n",
    "        raise FileNotFoundError(f\"County shapefile not found in {folder}\")\n",
    "\n",
    "    gdf = gpd.read_file(shp).to_crs(epsg=4326)\n",
    "    gdf = gdf[[\"STATEFP\", \"COUNTYFP\", \"NAME\", \"geometry\"]].rename(\n",
    "        columns={\"STATEFP\": \"statefp\", \"COUNTYFP\": \"countyfp\", \"NAME\": \"county_name\"}\n",
    "    )\n",
    "    # 조인 키(문자형 보장)\n",
    "    gdf[\"statefp\"] = gdf[\"statefp\"].astype(str).str.zfill(2)\n",
    "    gdf[\"countyfp\"] = gdf[\"countyfp\"].astype(str).str.zfill(3)\n",
    "    gdf[\"county_geoid\"] = gdf[\"statefp\"] + gdf[\"countyfp\"]\n",
    "    return gdf[[\"county_geoid\", \"county_name\"]]\n",
    "\n",
    "\n",
    "def add_tract_and_names(df: pd.DataFrame, lat_col=\"Latitude\", lon_col=\"Longitude\",\n",
    "                        year: int = 2023, cache_dir: str = \"./tiger_cache\") -> pd.DataFrame:\n",
    "\n",
    "    out = df.copy()\n",
    "    out[lat_col] = pd.to_numeric(out[lat_col], errors=\"coerce\")\n",
    "    out[lon_col] = pd.to_numeric(out[lon_col], errors=\"coerce\")\n",
    "\n",
    "    # 결과 컬럼 준비\n",
    "    for c in [\"tract_geoid\", \"tractce\", \"tract_name\", \"statefp\", \"state_name\", \"countyfp\", \"county_name\"]:\n",
    "        out[c] = pd.NA\n",
    "\n",
    "    # 포인트 생성\n",
    "    pts = gpd.GeoDataFrame(\n",
    "        out,\n",
    "        geometry=[\n",
    "            Point(xy) if pd.notna(xy[0]) and pd.notna(xy[1]) else None\n",
    "            for xy in zip(out[lon_col], out[lat_col])\n",
    "        ],\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "    valid = pts[pts.geometry.notna()].copy()\n",
    "    if len(valid) == 0:\n",
    "        return out\n",
    "\n",
    "    # 1) 먼저 County 폴리곤으로 statefp 후보를 좁혀서 tract 다운로드 최소화\n",
    "    #    (county는 전국 파일이 있으니 이를 사용)\n",
    "    counties_poly = gpd.read_file(\n",
    "        f\"https://www2.census.gov/geo/tiger/TIGER{year}/COUNTY/tl_{year}_us_county.zip\"\n",
    "    ).to_crs(epsg=4326)[[\"STATEFP\", \"geometry\"]]\n",
    "\n",
    "    tmp = gpd.sjoin(valid, counties_poly, how=\"left\", predicate=\"within\")\n",
    "    statefps = pd.Series(tmp[\"STATEFP\"].dropna().astype(str).str.zfill(2)).unique().tolist()\n",
    "\n",
    "    # 2) 해당 state들의 tract만 로딩해서 합치기\n",
    "    tract_frames = []\n",
    "    for s in statefps:\n",
    "        tract_frames.append(load_state_tracts(year, s, cache_dir))\n",
    "    tracts = pd.concat(tract_frames, ignore_index=True)\n",
    "\n",
    "    # 3) Tract 매칭\n",
    "    joined = gpd.sjoin(\n",
    "        valid, tracts, how=\"left\", predicate=\"within\",\n",
    "        lsuffix=\"pt\", rsuffix=\"tract\"\n",
    "    )\n",
    "\n",
    "    out.loc[joined.index, \"tract_geoid\"] = joined[\"tract_geoid_tract\"].values\n",
    "    out.loc[joined.index, \"tractce\"] = joined[\"tractce_tract\"].values\n",
    "    out.loc[joined.index, \"tract_name\"] = joined[\"tract_name_tract\"].values\n",
    "    out.loc[joined.index, \"statefp\"] = pd.Series(joined[\"statefp_tract\"]).astype(str).str.zfill(2).values\n",
    "    out.loc[joined.index, \"countyfp\"] = pd.Series(joined[\"countyfp_tract\"]).astype(str).str.zfill(3).values\n",
    "\n",
    "    # 4) State 이름 붙이기\n",
    "    out[\"state_name\"] = out[\"statefp\"].map(STATEFP_TO_NAME)\n",
    "\n",
    "    # 5) County 이름 붙이기 (STATEFP+COUNTYFP로 merge)\n",
    "    counties_names = load_us_counties(year, cache_dir)\n",
    "    out[\"county_geoid\"] = out[\"statefp\"].astype(\"string\") + out[\"countyfp\"].astype(\"string\")\n",
    "    out = out.merge(counties_names, on=\"county_geoid\", how=\"left\", suffixes=(\"\", \"_from_county\"))\n",
    "\n",
    "    # merge 결과 정리: county_name 최종 확정\n",
    "    out[\"county_name\"] = out[\"county_name\"].fillna(out[\"county_name_from_county\"])\n",
    "    out = out.drop(columns=[c for c in [\"county_name_from_county\", \"county_geoid\"] if c in out.columns])\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "    df2 = add_tract_and_names(df, lat_col=\"Latitude\", lon_col=\"Longitude\",\n",
    "                              year=TIGER_YEAR, cache_dir=CACHE_DIR)\n",
    "    df2.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(\"Saved:\", OUTPUT_CSV)\n",
    "    print(\"Matched tracts:\", df2[\"tract_geoid\"].notna().sum())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
